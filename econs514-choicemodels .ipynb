{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Fri Jan 20 13:40:18 2023\n@author: jiay\n\"\"\"\nimport os\nimport random\nimport multiprocessing as mp\nimport numpy as np\nimport pandas as pd\nimport scipy.optimize as opt\n\nclass ChoiceModels(object):\n    \n    '''\n    This class defines methods that will be used later in speficying and estimating choice models.\n    '''\n   \n    def load_data(self, path, file):\n        df = pd.read_csv(os.path.join(path, file), sep='\\s+', header=0)\n        df['cons'] = 1.\n        return df\n    \n    def expand_data(self, df, n):\n        '''\n        Parameters\n        ----------\n        df : a pandas data frame\n            \n        n : Integer\n            Number of times to expand the data\n        Returns\n        -------\n        An expanded pandas data frame with a panel structure\n        '''\n        df['Alt'] = [[str(i) for i in range(n)] for _ in range(len(df))]\n        return df.explode('Alt')\n    \n    def create_choice_attributes(self, df, config):\n        '''\n        This method creates a panel structure of data to estimate the multinomial\n        choice model speficied in the configuration file (config-- a json format file)\n        '''\n        # create dependent variable\n        df_copy = df.copy()\n        y_namelist = list(config['Alternatives']['0'].keys())\n        df_copy['choice'] = list(zip(*[df_copy[v] for v in y_namelist]))\n        df_copy = self.expand_data(df_copy, len(config['Alternatives']))\n   \n        df_copy['y'] = 0.\n        for k,v in config['Alternatives'].items():\n            label = tuple(v.values())\n            df_copy.loc[(df_copy[\"Alt\"]==k) & (df_copy['choice']==label), 'y'] = 1\n        \n        # create alternative specific attributes\n        dic = config['Attributes']\n        for var,info in dic.items():\n            df_copy[var] = 0\n            for alt, w in info['rule'].items():\n                df_copy['junk'] = 0\n                df_copy.loc[(df_copy['Alt'] == alt), 'junk'] = 1\n                df_copy[var] = df_copy[var] + w * df_copy[info['variable']] * df_copy['junk'] \n        df_copy = df_copy.drop(\"junk\", axis='columns')\n        \n        # creat interactions\n        df_copy, xz_list = self.create_interactions(df_copy, config['Interactions']) \n        return {'data': df_copy, \"xz\": xz_list}\n    \n    def create_interactions(self, df, interact_list):\n        '''\n        Parameters\n        ----------\n        df : pandas data frame\n            \n        interact_list : a List\n            The list contains pairs of variable names as tuples\n        Returns\n        -------\n        df : pandas data frame after adding interactions\n            \n        xz_list : A list of created interactions\n        '''\n        xz_list = []\n        if interact_list is None:\n            return df, xz_list\n        for item in interact_list:\n            vname = item[0] + \"_\" + item[1]\n            df[vname] = df[item[0]] * df[item[1]]\n            xz_list.append(vname)\n        return df, xz_list \n        \n        \n    def optimization(self, objfun, para):\n        '''\n        Parameters\n        ----------\n        objfun : a user defined objective function of para\n            \n        para : a 1-D array with the shape (k,), where k is the number of parameters.\n        Returns\n        -------\n        dict\n            A dictionary containing estimation results\n        '''\n        v = opt.minimize(objfun, x0=para, jac=None, method='BFGS', \n                          options={'maxiter': 1000, 'disp': True})  \n        return {'log_likelihood':-1*v.fun, \"Coefficients\": v.x, \"Var_Cov\": v.hess_inv}\n\n    def halton_sequence(self, ndraws, seed, randomize=True, shuffle=True, cut=100):\n        '''\n        This method generates Haton sequence for random drawing. \n        ndraws: an integer defining the length of generated sequece\n        seed: a prime number\n        \n        Return: a 1-D array with the shape (ndraws,) \n        '''\n        discard = random.randint(0, cut)\n        n = ndraws + discard;     \n        k = np.fix(np.log(n+1) / np.log(seed))\n        phi = np.zeros(1)\n        i = 1\n        while i <= k+1:\n            x = phi\n            j = 1\n            while j<seed:\n                y = phi + (j/seed**i)\n                x = np.concatenate((x, y))\n                j += 1\n            phi = x\n            i += 1\n            \n        x=phi\n        j=1\n        while j<seed and len(x) < n:\n            y=phi+(j/seed**i)\n            x = np.concatenate((x, y))\n            j += 1\n        phi=x[discard:n]\n        \n        if randomize is True:\n            phi = phi + np.random.rand()\n            phi[phi>=1] -= 1\n        \n        if shuffle is True:\n            random.shuffle(phi)\n        return phi\n    \nclass BinaryLogit(ChoiceModels):\n    '''\n    This class is to estimate a binary logit nodel by MLE.  \n    '''\n    def __init__(self, path, file, yname, x=None, z=None, interactions=None):\n        df = super().load_data(path, file)\n        if x is None:\n            x = []\n        if z is None:\n            z = []\n        if interactions is None:\n            xz = []\n            self.df = df\n        else:\n            self.df, xz = super().create_interactions(df, interactions)\n            \n        self.X_list = ['cons'] + x + z + xz\n        self.Xmat = self.df[self.X_list].to_numpy()\n        self.y = self.df[yname].to_numpy()\n        \n    def log_likelihood(self, para):\n        '''\n        Parameters\n        ----------\n        para : array\n            a 1-D array with the shape(k,), where k is the number of model parameters.\n        Returns\n        -------\n        res : scalar\n            log-likelihood value\n        '''\n        xb = np.matmul(self.Xmat, para)\n        xb = np.exp(xb)\n        xb = xb / (1+xb)\n        return (-1/len(xb)) * np.sum(self.y * np.log(xb) + (1-self.y) * np.log(1 - xb))\n   \n    def estimation(self, para):\n        '''\n        Parameters\n        ----------\n        para : array\n            a 1-D array with the shape(k,), where k is the number of model parameters.\n        Returns\n        -------\n        A dictionary of estimation results\n        '''\n        return super().optimization(self.log_likelihood, para)\n\nclass MultinomialLogit(ChoiceModels):\n\n    # Specify model here    \n    model_config = {\"Alternatives\":\n                    {\"0\": {\"trans\": 1, \"occupanc\": 1, \"route\": 1},\n                     \"1\": {\"trans\": 1, \"occupanc\": 1, \"route\": 0},\n                     \"2\": {\"trans\": 1, \"occupanc\": 2, \"route\": 1},\n                     \"3\": {\"trans\": 1, \"occupanc\": 2, \"route\": 0},\n                     \"4\": {\"trans\": 1, \"occupanc\": 3, \"route\": 1},\n                     \"5\": {\"trans\": 1, \"occupanc\": 3, \"route\": 0},\n                     \"6\": {\"trans\": 0, \"occupanc\": 1, \"route\": 0},\n                     \"7\": {\"trans\": 0, \"occupanc\": 2, \"route\": 0},\n                     \"8\": {\"trans\": 0, \"occupanc\": 3, \"route\": 0}},\n                    \"Nests\": {\"0\":{\"0\": [\"0\", \"1\"], \"1\": [\"2\", \"3\"], \n                                   \"2\": [\"4\", \"5\"]},\"1\":[\"6\", \"7\", \"8\"]},\n                    \"Attributes\":{'trans_dummy':{'variable': 'cons', \n                                                 'rule':{\"0\":1,\"1\":1,\n                                                         \"2\":1,\"3\":1,\"4\":1,\"5\":1}},\n                                  'express_dummy':{'variable':'cons', \n                                                   'rule':{\"0\":1,\"2\":1,\"4\":1}},\n                                  'hov2_dummy':{'variable':'cons', \n                                               'rule':{\"2\":1,\"3\":1,\"7\":1}},\n                                  \"hov3_dummy\":{'variable':'cons', \n                                                'rule':{\"4\":1,\"5\":1,\"8\":1}},\n                                  \"price\":{\"variable\": 'toll', \n                                           \"rule\": {\"0\":1,\"2\":1/2,\"4\":1/6}},\n                                  \"time\": {\"variable\":\"median\", \n                                           \"rule\":{\"0\":1,\"2\":1,\"4\":1}}},\n                    \"Interactions\":[('express_dummy', \"high_income\"), ('express_dummy', \"med_income\")],\n                    \"Mixedlogit\":{'fixed_coeffs':['express_dummy', 'express_dummy_high_income',\n                                                 'express_dummy_med_income'],\n                                  'random_coeffs':{'price':{'conditionals':['high_income', 'med_income'],\n                                                            'distribution':'-lognormal'},\n                                                   'time':{'conditionals':['distance'],\n                                                           'distribution':'normal'},\n                                                   'trans_dummy':{'conditionals':None, \n                                                                  'distribution':'normal'},\n                                                   'hov2_dummy':{'conditionals':['householdsize'],\n                                                                 'distribution':'normal'},\n                                                   'hov3_dummy':{'conditionals':['householdsize'],\n                                                                 'distribution':'normal'}},\n                                 'prime_numbers':[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, \n                                                  43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]}}\n    \n    \n    def __init__(self, path, file, model = \"mnl\", halton_draws=300):\n        self.halton_draws = halton_draws\n        df = super().load_data(path, file)\n        self.npersons = len(df)\n        self.nalts = len(MultinomialLogit.model_config['Alternatives'])\n        res = super().create_choice_attributes(df, MultinomialLogit.model_config)\n        y = res['data']['y'].to_numpy()\n        self.y_groupby = [y[i:i+self.nalts] for i in range(0,len(y),self.nalts)]\n        if model == \"mixed\":\n            self.X_list = MultinomialLogit.model_config['Mixedlogit']['fixed_coeffs']\n            prime = MultinomialLogit.model_config['Mixedlogit']['prime_numbers']\n            ndraws = self.npersons * self.halton_draws\n            self.random_components = [{} for _ in range(self.npersons)]\n            for k in MultinomialLogit.model_config['Mixedlogit']['random_coeffs'].keys():\n                # slicing data used in identifying random coefficients to individual level\n                x_k = [res['data'][k].to_numpy()[i:i+self.nalts] for i in range(0,len(y),self.nalts)] \n                if MultinomialLogit.model_config['Mixedlogit']['random_coeffs'][k]['conditionals'] is not None:\n                    z_k = df[MultinomialLogit.model_config['Mixedlogit']['random_coeffs'][k]['conditionals']].to_numpy()\n                \n                s = random.choice(prime)\n                sequence = super().halton_sequence(ndraws, s)\n                temp = [sequence[i:i+self.halton_draws] for i in range(0,len(sequence),self.halton_draws)]\n                for idx, item in enumerate(temp):\n                    self.random_components[idx][k]= {}\n                    self.random_components[idx][k]['x'] = x_k[idx]\n                    self.random_components[idx][k]['draws'] = item\n                    if MultinomialLogit.model_config['Mixedlogit']['random_coeffs'][k]['conditionals'] is not None:\n                        self.random_components[idx][k]['z'] = np.concatenate(([1], z_k[idx]))\n                    else: \n                        self.random_components[idx][k]['z'] = np.ones(1)\n                prime.remove(s)\n                \n        if model == \"mnl\":\n            self.X_list = list(MultinomialLogit.model_config['Attributes']) + res['xz']\n            \n        self.Xmat = res['data'][self.X_list].to_numpy()\n    \n    @staticmethod\n    def mnl_groupby(groupby_pair):\n        return np.sum(groupby_pair[0] * np.log((groupby_pair[1] / np.sum(groupby_pair[1]))))\n    \n    def mnl_log_likelihood(self, para):\n        '''\n        This method defines the data log-likelihood from a Multinomial Logit.\n        '''\n        xb = np.matmul(self.Xmat, para)\n        xb = np.exp(xb)\n        xb_groupby = [xb[i:i+self.nalts] for i in range(0,len(xb),self.nalts)]\n        return (-1/len(xb)) * sum(list(map(self.mnl_groupby, zip(self.y_groupby, xb_groupby))))\n    \n    def nl_log_likelihood(self, para):\n        pass\n    \n    @staticmethod\n    def mixed_utils(xb_g):\n        '''\n        xb_g: an 1-D array with shape (self.nalts, ) \n        '''\n        return xb_g / np.sum(xb_g)\n    \n    def mixed_groupby(self, groupby_pair):\n        '''\n        This method implements monte-carlo integration to compute choice probabilities of one person. \n        '''\n        brandom = groupby_pair[-1] \n        rp = groupby_pair[-2]\n        y = groupby_pair[0]\n        xb = np.kron(np.ones(self.halton_draws),groupby_pair[1])\n        start = 0\n        end = 0\n        for k, v in rp.items():\n            info = MultinomialLogit.model_config['Mixedlogit']['random_coeffs'][k]\n            end = end + len(v['z']) + 1\n            coef = np.matmul(v['z'], brandom[start:(end-1)]) + brandom[end] * v['draws']\n            if info.get('distribution', None) == \"-lognormal\":\n                coef = -1 * np.exp(coef)\n            \n            xb = xb + np.kron(coef, v['x'])\n            start = end\n        xb = np.exp(xb)\n        xb_groupby = [xb[i:i+self.nalts] for i in range(0,len(xb),self.nalts)]\n        res = y * np.log((1/self.halton_draws)*sum(list(map(self.mixed_utils, xb_groupby))))\n        return np.sum(res)\n    \n    def mixed_log_likelihood(self, para):\n        '''\n        Define log-likelihood function for mixed-logit\n        '''\n        bfixed = para[0:len(self.X_list)]\n        brandom = [para[len(self.X_list):len(para)] for _ in range(self.npersons)]\n        xb = np.matmul(self.Xmat, bfixed)\n        xb_groupby = [xb[i:i+self.nalts] for i in range(0,len(xb),self.nalts)]\n        pack = list(zip(self.y_groupby, xb_groupby, self.random_components, brandom))\n        return (-1/len(xb)) * sum(list(map(self.mixed_groupby, pack)))\n \n    def estimation(self, para):\n        '''\n        Parameters\n        ----------\n        para : array\n            a 1-D array with the shape(k,), where k is the number of model parameters.\n        Returns\n        -------\n        A dictionary of estimation results\n        '''\n        return super().optimization(self.mnl_log_likelihood, para)\n    \nif __name__ == '__main__':\n    p =r\"/kaggle/input/travel-choice\"\n    f = \"assignment 1.txt\"\n    ## estimating binary models\n    x = ['toll', 'median']\n    z = ['female', 'age3050', 'distance', 'householdsize']\n    interactions = [('toll', 'high_income'), ('toll', 'med_income')]\n    route = BinaryLogit(p, f, \"route\", x=x, z=z, interactions=interactions)\n    bini = np.zeros(len(route.X_list))\n    res_binary = route.estimation(bini)\n    \n    ## estimating a MNL model\n    import time\n    start = time.time()\n    mnl = MultinomialLogit(p, f, model=\"mnl\")\n    bini = np.zeros(len(mnl.X_list))\n    res_mnl = mnl.estimation(bini)\n    end = time.time()\n    print(end - start)\n    \n    ## estimating a mixed-logit model\n    mixed = MultinomialLogit(p, f, model=\"mixed\")\n    nparameters = len(mnl.X_list) + 15\n    bini = np.zeros(nparameters)\n    es_mixed = mixed.mixed_log_likelihood(bini) ","metadata":{"execution":{"iopub.status.busy":"2023-02-06T00:20:55.790014Z","iopub.execute_input":"2023-02-06T00:20:55.790418Z","iopub.status.idle":"2023-02-06T00:21:04.282082Z","shell.execute_reply.started":"2023-02-06T00:20:55.790384Z","shell.execute_reply":"2023-02-06T00:21:04.281041Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"Optimization terminated successfully.\n         Current function value: 0.528810\n         Iterations: 34\n         Function evaluations: 370\n         Gradient evaluations: 37\nOptimization terminated successfully.\n         Current function value: 0.204334\n         Iterations: 60\n         Function evaluations: 558\n         Gradient evaluations: 62\n5.6868736743927\n","output_type":"stream"}]},{"cell_type":"code","source":"mixed.mixed_groupby(es_mixed[0])\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T23:04:20.781353Z","iopub.execute_input":"2023-02-05T23:04:20.782573Z","iopub.status.idle":"2023-02-05T23:04:20.798614Z","shell.execute_reply.started":"2023-02-05T23:04:20.782518Z","shell.execute_reply":"2023-02-05T23:04:20.797348Z"},"trusted":true},"execution_count":108,"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"-21.110070867537214"},"metadata":{}}]},{"cell_type":"code","source":"np.kron([1,2,3,4,5,6,7], [5,6,7])","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:05:39.143778Z","iopub.execute_input":"2023-02-05T06:05:39.144169Z","iopub.status.idle":"2023-02-05T06:05:39.153181Z","shell.execute_reply.started":"2023-02-05T06:05:39.144136Z","shell.execute_reply":"2023-02-05T06:05:39.151938Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array([ 5,  6,  7, 10, 12, 14, 15, 18, 21, 20, 24, 28, 25, 30, 35, 30, 36,\n       42, 35, 42, 49])"},"metadata":{}}]},{"cell_type":"code","source":"l = mnl.mnl_log_likelihood(bini, mp=False)\nl","metadata":{"execution":{"iopub.status.busy":"2023-01-31T05:57:50.876965Z","iopub.execute_input":"2023-01-31T05:57:50.877392Z","iopub.status.idle":"2023-01-31T05:57:51.039726Z","shell.execute_reply.started":"2023-01-31T05:57:50.877359Z","shell.execute_reply":"2023-01-31T05:57:51.038492Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"0.2441360641484688"},"metadata":{}}]},{"cell_type":"code","source":"list(zip(np.array([1,2,3]), [4,5,6], [7,8,9]))","metadata":{"execution":{"iopub.status.busy":"2023-02-05T18:40:57.383614Z","iopub.execute_input":"2023-02-05T18:40:57.384054Z","iopub.status.idle":"2023-02-05T18:40:57.394233Z","shell.execute_reply.started":"2023-02-05T18:40:57.384017Z","shell.execute_reply":"2023-02-05T18:40:57.393089Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"[(1, 4, 7), (2, 5, 8), (3, 6, 9)]"},"metadata":{}}]},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"code","source":"p = route.halton_sequence(10, 2)\np","metadata":{"execution":{"iopub.status.busy":"2023-01-29T20:40:08.823789Z","iopub.execute_input":"2023-01-29T20:40:08.824134Z","iopub.status.idle":"2023-01-29T20:40:08.831275Z","shell.execute_reply.started":"2023-01-29T20:40:08.824107Z","shell.execute_reply":"2023-01-29T20:40:08.830297Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([0.0533552, 0.1783552, 0.0064802, 0.4283552, 0.9283552, 0.5064802,\n       0.3033552, 0.6783552, 0.8033552, 0.5533552])"},"metadata":{}}]},{"cell_type":"code","source":"len(mnl.halton['price'])\n","metadata":{"execution":{"iopub.status.busy":"2023-01-29T23:37:20.707518Z","iopub.execute_input":"2023-01-29T23:37:20.708019Z","iopub.status.idle":"2023-01-29T23:37:20.719011Z","shell.execute_reply.started":"2023-01-29T23:37:20.707979Z","shell.execute_reply":"2023-01-29T23:37:20.717235Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"131400"},"metadata":{}}]},{"cell_type":"code","source":"mnl.Xmat.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-29T23:38:00.981723Z","iopub.execute_input":"2023-01-29T23:38:00.982338Z","iopub.status.idle":"2023-01-29T23:38:00.991391Z","shell.execute_reply.started":"2023-01-29T23:38:00.982273Z","shell.execute_reply":"2023-01-29T23:38:00.989975Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(3942, 3)"},"metadata":{}}]},{"cell_type":"code","source":"l = [1,2,3,4,5,6]\nl[0:2]\nl[2:len(l)]","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:51:15.729400Z","iopub.execute_input":"2023-01-30T00:51:15.729789Z","iopub.status.idle":"2023-01-30T00:51:15.738358Z","shell.execute_reply.started":"2023-01-30T00:51:15.729757Z","shell.execute_reply":"2023-01-30T00:51:15.736966Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[3, 4, 5, 6]"},"metadata":{}}]},{"cell_type":"code","source":"np.log(sum([1,2]))","metadata":{"execution":{"iopub.status.busy":"2023-02-05T20:14:15.158238Z","iopub.execute_input":"2023-02-05T20:14:15.158614Z","iopub.status.idle":"2023-02-05T20:14:15.165476Z","shell.execute_reply.started":"2023-02-05T20:14:15.158584Z","shell.execute_reply":"2023-02-05T20:14:15.164445Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"1.0986122886681098"},"metadata":{}}]},{"cell_type":"code","source":"l = [np.array([1,2,3]), np.array([4,5,6])]\nsum(l)","metadata":{"execution":{"iopub.status.busy":"2023-02-05T21:11:32.150560Z","iopub.execute_input":"2023-02-05T21:11:32.150970Z","iopub.status.idle":"2023-02-05T21:11:32.158283Z","shell.execute_reply.started":"2023-02-05T21:11:32.150934Z","shell.execute_reply":"2023-02-05T21:11:32.157088Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"array([5, 7, 9])"},"metadata":{}}]}]}